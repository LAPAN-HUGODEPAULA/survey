# Add LLM as a Judge for Output Validation

## Context

The recent version of the system have 4 agents:

- InputValidatorAgent
- JsonProcessorAgent
- ConversationProcessorAgent
- OtherInputHandlerAgent

The following code show how the agent graph is created:

```python
workflow = StateGraph(AgentState)

    # Add nodes
    workflow.add_node("validate_and_classify", InputValidatorAgent().validate_and_classify)
    workflow.add_node("process_conversation", ConversationProcessorAgent(llm_model=conversation_llm).process)
    workflow.add_node("process_json", JsonProcessorAgent(llm_model=json_llm).process)
    workflow.add_node("handle_other", OtherInputHandlerAgent().handle)

    # Set entry point
    workflow.set_entry_point("validate_and_classify")

    # Define conditional edges based on classification
    workflow.add_conditional_edges(
        "validate_and_classify",
        lambda state: state["classification"],
        {
            AgentConfig.CLASSIFICATION_CONVERSATION: "process_conversation",
            AgentConfig.CLASSIFICATION_JSON: "process_json",
            AgentConfig.CLASSIFICATION_INAPPROPRIATE: "handle_other",
            AgentConfig.CLASSIFICATION_OTHER: "handle_other",
        },
    )

    # Define normal edges
    workflow.add_edge("process_conversation", END)
    workflow.add_edge("process_json", END)
    workflow.add_edge("handle_other", END)

```

When a request arrives to the system, it is first processed by the InputValidatorAgent. This agent validates the input and uses the strategy pattern to call different classification strategies.

Depending on the classification, the request is routed to one of the processing agents: ConversationProcessorAgent, JsonProcessorAgent, or OtherInputHandlerAgent. Each of these agents processes the input accordingly and generates an output.

## TASK: Integrate an LLM as a Judge for Output Validation

You task as an experienced software engineer and knowleagedgeable in AI agent development is to enhance the existing system by integrating a Large Language Model (LLM) as a judge to validate the outputs generated by the processing agents. Your task must implement the following requirements:

1. The InputValidatorAgent must receive the content from the httprequest and perform initial validation checks (e.g., format, length, basic content checks) before classification. It also must sanitize data, remove html and scripts tags, and trim excessive whitespace.

2. The InputValidatorAgent then must  send to an llm as a judge to validate the input before classification. The first judge must check for appropriateness and relevance of the input content. The judge llm must return a score from 0 to 1 indicating the appropriateness of the content. If the score is below a certain threshold (e.g., 0.5), the InputValidatorAgent should classify the input as inappropriate and route it to the OtherInputHandlerAgent, using AgentConfig.CLASSIFICATION_FLAGGED and AgentConfig.ERROR_MSG_INAPPROPRIATE_CONTENT.

3. If the input passes the appropriateness check, the InputValidatorAgent must then classify the input using its existing classification strategies (e.g., conversation, JSON, other). You must create another Agent that will receive the input_content from the InputValidatorAgent and use and classify the content using the strategy pattern. In this new graph, InputValidatorAgent will route the input to this new Agent for classification and will not be responsible for classification. It provides a better separation of concerns, where InputValidatorAgent focuses solely on validation and the new ClassificationAgent focuses on classification. You must improve the Json valitation strategy, since it is not working properly. It must validate if the input is a valid JSON schema, even if the contnent is in string format, for example: '{"key": "value"}'.

4. After classification, the InputValidatorAgent must route the input to the appropriate processing agent (ConversationProcessorAgent, JsonProcessorAgent, or OtherInputHandlerAgent) based on the classification result.

## STEPS to Accomplish the Task

1. Review the existing InputValidatorAgent to understand its validation and classification logic.
2. Modularize the code: Extract the classification logic from InputValidatorAgent into a new ClassificationAgent; create a classification strategy module with the strategy pattern implementation.
3. Integrate the LLM as a judge in the InputValidatorAgent to validate input content before classification.
4. Update the workflow graph to include the new ClassificationAgent and adjust routing logic accordingly.
5. Update documentation and comments to reflect the changes made.

## Observations

### Environment and Tooling

- Package Manager: The project must use `uv` for dependency management. `pip` should not be used with the systemâ€™s native Python installation.
- Virtual Environment: The project is configured to use a virtual environment located in the .venv directory.
- Activating the Environment: To activate the virtual environment, run the following command from the project root: source .venv/bin/activate

### Development Best Practices

- Version Control: All code must be versioned using Git.
- Code Comments: Code should be adequately commented to explain complex logic.
- Module Docstrings: Module-level docstrings should be more extensive than the typical standard. They must include a theoretical introduction to
the topic being handled in that module.
- Code Architecture: The code must be modular and follow object-oriented best practices, specifically the SOLID principles, with a focus on
extensibility and adaptability.
